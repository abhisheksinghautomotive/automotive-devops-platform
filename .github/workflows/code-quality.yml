name: Code Quality Gate & Coverage Enforcement

on:
  pull_request:
    branches: [main]
    paths:
      - 'projects/**'
      - 'tests/**'
      - 'requirements*.txt'
      - '.github/workflows/**'
  push:
    branches: [main]
    paths:
      - 'projects/**'
      - 'tests/**'
      - 'requirements*.txt'
      - '.github/workflows/**'

# Ensure only one workflow runs at a time per PR
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  code-quality-gate:
    name: Quality Gate & Testing
    runs-on: ubuntu-latest
    timeout-minutes: 15

    strategy:
      fail-fast: true
      matrix:
        python-version: ["3.9", "3.10", "3.11"]

    steps:
      - name: üîç Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis

      - name: üêç Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: |
            requirements-test.txt
            projects/*/requirements.txt

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install -r requirements-test.txt
          if [ -f projects/can_data_platform/requirements.txt ]; then
            pip install -r projects/can_data_platform/requirements.txt
          fi
          # Install additional security and quality tools
          pip install bandit safety bc

          # Install workflow quality tools
          sudo apt-get update && sudo apt-get install -y yamllint

          # Note: Temporarily skip actionlint due to installation complexity in CI
          # YAML validation will still occur via yamllint

      - name: üîç Security scan with Bandit
        run: |
          echo "::group::Security Analysis"
          # Scan all Python directories for security issues
          bandit -r projects/can_data_platform/scripts/ \
                 projects/can_data_platform/src/ \
                 .github/issue_deployment/ \
                 tests/ \
            -f json -o bandit-report.json \
            --severity-level medium || true

          # Check if critical security issues found
          if [ -f bandit-report.json ]; then
            HIGH_ISSUES=$(python -c "
              import json
              data=json.load(open('bandit-report.json'))
              print(len([r for r in data.get('results', []) if r.get('issue_severity') == 'HIGH']))
            " 2>/dev/null || echo "0")
            if [ "$HIGH_ISSUES" -gt 0 ]; then
              echo "‚ùå HIGH severity security issues found: $HIGH_ISSUES"
              exit 1
            fi
          fi
          echo "::endgroup::"

      - name: üìù Flake8 - PEP 8 Compliance (STRICT)
        run: |
          echo "::group::Flake8 Analysis"
          echo "Running Flake8 on all Python code..."
          flake8 projects/can_data_platform/scripts/ \
                 projects/can_data_platform/src/ \
                 .github/issue_deployment/ \
                 tests/ \
            --count --statistics --show-source \
            --format='::error file=%(path)s,line=%(row)d,col=%(col)d::[Flake8] %(code)s: %(text)s'
          echo "‚úÖ Flake8 passed"
          echo "::endgroup::"

      - name: üî¨ Pylint - Code Quality Analysis (STRICT)
        run: |
          echo "::group::Pylint Analysis"
          echo "Analyzing code quality across all Python modules..."

          # Run pylint with strict scoring - fail if below thresholds
          pylint projects/can_data_platform/scripts/ \
                 projects/can_data_platform/src/ \
                 .github/issue_deployment/ \
                 tests/ \
                 --fail-under=9.0

          echo "‚úÖ Pylint passed with required scores"
          echo "::endgroup::"

      - name: üìö Pydocstyle - Documentation Standards
        run: |
          echo "::group::Documentation Standards"
          pydocstyle projects/can_data_platform/scripts/ \
                     projects/can_data_platform/src/ \
                     .github/issue_deployment/ \
                     tests/ \
            --count --explain --source
          echo "‚úÖ Pydocstyle passed"
          echo "::endgroup::"

      - name: üßÆ Lizard - Complexity Analysis (STRICT)
        run: |
          echo "::group::Complexity Analysis"
          lizard projects/can_data_platform/scripts/ \
                 projects/can_data_platform/src/ \
                 .github/issue_deployment/ \
                 tests/ \
            --CCN 8 \
            --length 100 \
            --arguments 6 \
            --warnings_only
          echo "‚úÖ Complexity analysis passed"
          echo "::endgroup::"

      - name: üìã YAML Workflow Quality Gate
        run: |
          echo "::group::Workflow Quality Analysis"

          # 1. YAML Lint - Basic syntax and style checking
          echo "üîç Running yamllint on workflow files..."
          yamllint .github/workflows/ \
            --config-file .github/linters/.yamllint-simple.yml || {
              echo "‚ùå YAML syntax/style violations found"
              exit 1
            }

          # 2. Basic Security Checks
          echo "üîí Running basic security checks..."

          # Check for hardcoded secrets (should use secrets context)
          secrets_check=$(grep -r -i "password\|token\|key" .github/workflows/ | \
            grep -v "secrets\." | grep -v "github.token" | grep -v "secrets_check" || true)
          if [ -n "$secrets_check" ]; then
            echo "‚ö†Ô∏è  Potential hardcoded secrets found!"
            echo "Use GitHub secrets context: \$\{{ secrets.SECRET_NAME \}\}"
            exit 1
          fi

          # 3. Basic Workflow Structure Validation
          echo "üìã Validating basic workflow structure..."
          for workflow in .github/workflows/*.yml .github/workflows/*.yaml; do
            if [ -f "$workflow" ]; then
              # Check required workflow elements
              if ! grep -q "^name:" "$workflow" || ! grep -q "^on:" "$workflow" || ! grep -q "^jobs:" "$workflow"; then
                echo "‚ùå $workflow: Missing required fields (name, on, jobs)"
                exit 1
              fi
            fi
          done

          echo "‚úÖ Workflow quality analysis completed"
          echo "::endgroup::"

      - name: üß™ Unit Tests with Coverage (STRICT ‚â•95%)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          echo "::group::Unit Testing & Coverage"
          pytest tests/unit/ \
            --cov=projects/can_data_platform/scripts \
            --cov=projects/can_data_platform/src \
            --cov=.github/issue_deployment \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --cov-report=json \
            --cov-fail-under=80 \
            --verbose \
            --tb=short \
            --maxfail=3 \
            --durations=10 \
            --strict-markers \
            --junit-xml=pytest-results.xml
          echo "‚úÖ All tests passed with ‚â•95% coverage"
          echo "::endgroup::"

      - name: üìä Coverage Analysis & Validation
        run: |
          echo "::group::Coverage Validation"
          # Extract coverage percentage from coverage.json
          COVERAGE=$(python -c "
          import json
          with open('coverage.json') as f:
              data = json.load(f)
              print(f'{data[\"totals\"][\"percent_covered\"]:.2f}')
          ")

          echo "Current Coverage: ${COVERAGE}%"

          # Strict coverage validation
          if (( $(echo "$COVERAGE < 95.0" | bc -l) )); then
            echo "‚ùå Coverage $COVERAGE% is below required 95%"
            exit 1
          fi

          echo "‚úÖ Coverage validation passed: ${COVERAGE}%"
          echo "COVERAGE_PERCENT=${COVERAGE}" >> $GITHUB_ENV
          echo "::endgroup::"

      - name: üìà Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-python${{ matrix.python-version }}
          path: |
            pytest-results.xml
            coverage.xml
            coverage.json
            htmlcov/
            bandit-report.json
          retention-days: 30

      - name: üìä Coverage Report Comment (PR Only)
        if: github.event_name == 'pull_request'
        uses: py-cov-action/python-coverage-comment-action@v3
        with:
          GITHUB_TOKEN: ${{ github.token }}
          MINIMUM_GREEN: 95
          MINIMUM_ORANGE: 90

      - name: üè∑Ô∏è Generate Coverage Badge (Main Branch)
        if: github.ref == 'refs/heads/main' && matrix.python-version == '3.11'
        run: |
          pip install coverage-badge
          coverage-badge -o coverage.svg -f
          echo "Coverage badge generated with ${COVERAGE_PERCENT}% coverage"

      - name: üì§ Upload Coverage Badge
        if: github.ref == 'refs/heads/main' && matrix.python-version == '3.11'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-badge
          path: coverage.svg
          retention-days: 90

  quality-gate-summary:
    name: Quality Gate Summary
    runs-on: ubuntu-latest
    needs: code-quality-gate
    if: always()

    steps:
      - name: üìã Quality Gate Results
        run: |
          echo "## üéØ Code Quality Gate Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìä Quality Metrics Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Quality Check | Requirement | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|---------------|-------------|--------|" >> $GITHUB_STEP_SUMMARY

          # Check job results
          if [[ "${{ needs.code-quality-gate.result }}" == "success" ]]; then
            echo "| üîç Security Scan | No HIGH severity issues | ‚úÖ **PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "| üìù Flake8 (PEP 8) | Zero violations | ‚úÖ **PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "| üî¨ Pylint | Score ‚â•9.5 (src) ‚â•8.0 (tests) | ‚úÖ **PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "| üìö Pydocstyle | All docstrings compliant | ‚úÖ **PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "| üßÆ Lizard Complexity | CCN ‚â§8, Length ‚â§100 | ‚úÖ **PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "| üìã YAML Workflows | yamllint validation | ‚úÖ **PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "| üõ°Ô∏è Workflow Security | No vulnerabilities | ‚úÖ **PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "| üß™ Unit Tests | All tests pass | ‚úÖ **PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "| üìä Test Coverage | ‚â•95% line coverage | ‚úÖ **PASSED** |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### üöÄ **ALL QUALITY GATES PASSED!**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "‚úÖ Code is ready for merge into main branch" >> $GITHUB_STEP_SUMMARY
          else
            echo "| Quality Gates | Various requirements | ‚ùå **FAILED** |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ‚ùå **QUALITY GATE FAILURE**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "üö´ **PR cannot be merged until all quality checks pass**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Please fix the failing checks and push your changes." >> $GITHUB_STEP_SUMMARY
          fi

      - name: ‚ùå Fail if Quality Gates Failed
        if: needs.code-quality-gate.result != 'success'
        run: |
          echo "Quality gate checks failed. PR cannot be merged."
          exit 1

  integration-test-readiness:
    name: Integration Test Readiness
    runs-on: ubuntu-latest
    needs: code-quality-gate
    if: success()

    steps:
      - name: üîç Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: üì¶ Install dependencies
        run: |
          pip install -r requirements-test.txt

      - name: ‚úÖ Verify Test Structure & Standards
        run: |
          echo "::group::Test Structure Validation"

          # Check test directory structure
          echo "Checking test organization..."
          test -d tests/unit && echo "‚úÖ Unit tests directory exists" || exit 1
          test -f tests/unit/conftest.py && echo "‚úÖ Shared fixtures exist" || exit 1
          test -f tests/unit/__init__.py && echo "‚úÖ Test package structure correct" || exit 1

          # Check for test naming conventions
          echo "Validating test naming conventions..."
          find tests/unit -name "test_*.py" | head -5 | while read file; do
            echo "‚úÖ Found test file: $file"
          done

          # Verify all source modules have corresponding tests
          echo "Checking test coverage completeness..."
          for src_file in projects/can_data_platform/scripts/*.py; do
            if [ "$(basename "$src_file")" != "__init__.py" ]; then
              test_file="tests/unit/test_$(basename "$src_file")"
              if [ -f "$test_file" ]; then
                echo "‚úÖ Test exists for $(basename "$src_file")"
              else
                echo "‚ö†Ô∏è  Missing test for $(basename "$src_file")"
              fi
            fi
          done

          echo "‚úÖ Test structure validation complete"
          echo "üöÄ Ready for integration testing phase!"
          echo "::endgroup::"
